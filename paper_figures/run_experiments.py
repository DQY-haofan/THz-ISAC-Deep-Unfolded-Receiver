#!/usr/bin/env python3
"""
run_experiments.py - ä¸»å…¥å£è„šæœ¬

è¿è¡Œå®Œæ•´çš„å®éªŒæµç¨‹ï¼š
1. åŠ è½½æ¨¡å‹
2. è¿è¡Œå„ç§ sweepï¼ˆæ•°æ®é‡‡é›†ï¼‰
3. ç”Ÿæˆå›¾è¡¨ï¼ˆå¯è§†åŒ–ï¼‰

ç”¨æ³•ï¼š
    # å®Œæ•´è¿è¡Œï¼ˆæ•°æ®é‡‡é›† + å¯è§†åŒ–ï¼‰
    python run_experiments.py --ckpt path/to/checkpoint.pth --n_mc 20

    # å¿«é€Ÿæµ‹è¯•
    python run_experiments.py --ckpt path/to/checkpoint.pth --quick

    # ä»…å¯è§†åŒ–ï¼ˆä»å·²æœ‰ CSV æ•°æ®ï¼‰
    python run_experiments.py --visualize_only --data_dir results/paper_figs
"""

import os
import sys
import argparse
import glob

# æ·»åŠ å½“å‰ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from evaluator import (
    EvalConfig,
    load_model,
    run_snr_sweep,
    run_cliff_sweep,
    run_snr_sweep_multi_init_error,
    run_ablation_sweep,
    run_heatmap_sweep,
    run_pn_sweep,
    run_pilot_sweep,
    run_jacobian_analysis,
    measure_latency,
)
from visualization import generate_all_figures
from baselines import METHOD_ORDER


def find_checkpoint(ckpt_path: str) -> str:
    """æŸ¥æ‰¾ checkpoint æ–‡ä»¶"""
    if ckpt_path and os.path.exists(ckpt_path):
        return ckpt_path

    patterns = [
        'results/checkpoints/Stage2_*/final.pth',
        './results/checkpoints/Stage2_*/final.pth',
        '../results/checkpoints/Stage2_*/final.pth',
    ]

    for pattern in patterns:
        matches = glob.glob(pattern)
        if matches:
            return sorted(matches)[-1]

    return None


def run_data_collection(args):
    """è¿è¡Œæ•°æ®é‡‡é›†é˜¶æ®µ"""

    print("=" * 60)
    print("ğŸ“Š æ•°æ®é‡‡é›†é˜¶æ®µ")
    print("=" * 60)

    # åŠ è½½æ¨¡å‹
    ckpt_path = find_checkpoint(args.ckpt)
    if not ckpt_path:
        print("ERROR: No checkpoint found!")
        return None

    print(f"Loading model from: {ckpt_path}")
    model, gabv_cfg = load_model(ckpt_path, args.device)

    # é…ç½®
    eval_cfg = EvalConfig(
        ckpt_path=ckpt_path,
        device=args.device,
        snr_list=args.snr_list,
        n_mc=args.n_mc if not args.quick else 5,
        batch_size=args.batch if not args.quick else 32,
        theta_noise_tau=args.init_error,
        out_dir=args.out_dir,
    )

    os.makedirs(args.out_dir, exist_ok=True)

    print(f"\nConfiguration:")
    print(f"  SNR list: {eval_cfg.snr_list}")
    print(f"  Monte Carlo trials: {eval_cfg.n_mc}")
    print(f"  Batch size: {eval_cfg.batch_size}")
    print(f"  Init error (Ï„): {eval_cfg.theta_noise_tau}")
    print(f"  Output: {args.out_dir}")

    # è¿è¡Œå„ç§ sweep
    print("\n" + "-" * 40)
    print("[1/7] SNR sweep...")
    df_snr = run_snr_sweep(model, gabv_cfg, eval_cfg)
    df_snr.to_csv(f"{args.out_dir}/data_snr_sweep.csv", index=False)
    print(f"      Saved: data_snr_sweep.csv ({len(df_snr)} records)")

    print("\n[2/7] Cliff sweep (ALL methods) - æ–¹æ¡ˆ1...")
    df_cliff = run_cliff_sweep(model, gabv_cfg, eval_cfg)
    df_cliff.to_csv(f"{args.out_dir}/data_cliff_sweep.csv", index=False)
    print(f"      Saved: data_cliff_sweep.csv ({len(df_cliff)} records)")

    print("\n[3/7] SNR sweep @ multi init_error - æ–¹æ¡ˆ3...")
    df_snr_multi = run_snr_sweep_multi_init_error(model, gabv_cfg, eval_cfg)
    df_snr_multi.to_csv(f"{args.out_dir}/data_snr_multi_init_error.csv", index=False)
    print(f"      Saved: data_snr_multi_init_error.csv ({len(df_snr_multi)} records)")

    print("\n[4/8] Ablation sweep - æ–¹æ¡ˆ2...")
    df_ablation = run_ablation_sweep(model, gabv_cfg, eval_cfg)
    df_ablation.to_csv(f"{args.out_dir}/data_ablation_sweep.csv", index=False)
    print(f"      Saved: data_ablation_sweep.csv ({len(df_ablation)} records)")

    print("\n[5/8] Heatmap sweep (2D: SNR Ã— init_error)...")
    df_heatmap = run_heatmap_sweep(model, gabv_cfg, eval_cfg)
    df_heatmap.to_csv(f"{args.out_dir}/data_heatmap_sweep.csv", index=False)
    print(f"      Saved: data_heatmap_sweep.csv ({len(df_heatmap)} records)")

    print("\n[6/8] PN sweep...")
    df_pn = run_pn_sweep(model, gabv_cfg, eval_cfg)
    df_pn.to_csv(f"{args.out_dir}/data_pn_sweep.csv", index=False)
    print(f"      Saved: data_pn_sweep.csv ({len(df_pn)} records)")

    print("\n[7/8] Pilot sweep...")
    df_pilot = run_pilot_sweep(model, gabv_cfg, eval_cfg)
    df_pilot.to_csv(f"{args.out_dir}/data_pilot_sweep.csv", index=False)
    print(f"      Saved: data_pilot_sweep.csv ({len(df_pilot)} records)")

    print("\n[8/8] Jacobian analysis & Latency...")
    df_jacobian = run_jacobian_analysis(model, gabv_cfg, eval_cfg)
    df_jacobian.to_csv(f"{args.out_dir}/data_jacobian.csv", index=False)

    df_latency = measure_latency(model, gabv_cfg, eval_cfg)
    df_latency.to_csv(f"{args.out_dir}/data_latency.csv", index=False)
    print(f"      Saved: data_jacobian.csv, data_latency.csv")

    # æ‰“å°ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç»“æœæ‘˜è¦")
    print("=" * 60)

    # éªŒè¯ baseline åœ¨ init_error=0 æ—¶çš„è¡¨ç°
    print("\n### ä¸“å®¶éªŒè¯ï¼šBaseline @ init_error=0")
    cliff_0 = df_cliff[df_cliff['init_error'] == 0.0]
    if len(cliff_0) > 0:
        for method in cliff_0['method'].unique():
            ber = cliff_0[cliff_0['method'] == method]['ber'].mean()
            status = "âœ… OK" if ber < 0.2 else "âš ï¸ å¼‚å¸¸"
            print(f"  {method:25s}: BER={ber:.4f} {status}")

    # SNR=15dB æ€§èƒ½
    print("\n### @ SNR=15dB")
    snr_15 = df_snr[df_snr['snr_db'] == 15]
    if len(snr_15) > 0:
        for method in ['adjoint_slice', 'proposed', 'oracle']:
            data = snr_15[snr_15['method'] == method]
            if len(data) > 0:
                ber = data['ber'].mean()
                rmse = data['rmse_tau_final'].mean()
                print(f"  {method:25s}: BER={ber:.4f}, RMSE={rmse:.4f}")

    return args.out_dir


def main():
    parser = argparse.ArgumentParser(
        description="Run experiments and generate paper figures",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Full run with data collection and visualization
  python run_experiments.py --ckpt checkpoint.pth --n_mc 20

  # Quick test
  python run_experiments.py --ckpt checkpoint.pth --quick

  # Visualization only (from existing CSV data)
  python run_experiments.py --visualize_only --data_dir results/paper_figs
        """
    )

    # æ¨¡å¼é€‰æ‹©
    parser.add_argument('--visualize_only', action='store_true',
                        help="Only generate figures from existing CSV data")

    # æ•°æ®é‡‡é›†å‚æ•°
    parser.add_argument('--ckpt', type=str, default="",
                        help="Checkpoint path")
    parser.add_argument('--snr_list', nargs='+', type=float,
                        default=[-5, 0, 5, 10, 15, 20, 25],
                        help="SNR values to sweep")
    parser.add_argument('--n_mc', type=int, default=20,
                        help="Monte Carlo trials")
    parser.add_argument('--batch', type=int, default=64,
                        help="Batch size")
    parser.add_argument('--init_error', type=float, default=0.3,
                        help="Default init Ï„ error (samples)")
    parser.add_argument('--device', type=str, default="cuda",
                        help="Device (cuda/cpu)")
    parser.add_argument('--quick', action='store_true',
                        help="Quick mode for testing")

    # è¾“å‡ºå‚æ•°
    parser.add_argument('--out_dir', type=str, default="results/paper_figs",
                        help="Output directory")
    parser.add_argument('--data_dir', type=str, default=None,
                        help="Data directory (for visualize_only mode)")

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ“ Paper Figure Generation Pipeline")
    print("=" * 60)
    print(f"Mode: {'Visualize Only' if args.visualize_only else 'Full Run'}")

    if args.visualize_only:
        # ä»…å¯è§†åŒ–æ¨¡å¼
        data_dir = args.data_dir or args.out_dir
        if not os.path.exists(data_dir):
            print(f"ERROR: Data directory not found: {data_dir}")
            return

        generate_all_figures(data_dir, args.out_dir)
    else:
        # å®Œæ•´è¿è¡Œæ¨¡å¼
        data_dir = run_data_collection(args)

        if data_dir:
            print("\n" + "=" * 60)
            print("ğŸ“ˆ å¯è§†åŒ–é˜¶æ®µ")
            print("=" * 60)
            generate_all_figures(data_dir, args.out_dir)

    # æœ€ç»ˆè¾“å‡º
    print("\n" + "=" * 60)
    print("ğŸ“ è®ºæ–‡å™äº‹å»ºè®®")
    print("=" * 60)
    print("""
"åœ¨ 1-bit é‡åŒ–ä¸è„ç¡¬ä»¶ THz-ISAC é“¾è·¯ä¸­ï¼Œåˆå§‹åŒæ­¥è¯¯å·®ä¼šè§¦å‘æ£€æµ‹
'æ‚¬å´–å¼å¤±æ•ˆ'ï¼›æœ¬æ–‡æå‡ºçš„ pilot-only å‡ ä½•ä¸€è‡´ Ï„ å¿«ç¯è·Ÿè¸ªå°†æ¥æ”¶æœº
é‡æ–°æ‹‰å›å¯è·Ÿè¸ªç›†åœ°ï¼Œä½¿æ£€æµ‹æ€§èƒ½åœ¨è¯¥ç›†åœ°å†…é€¼è¿‘ oracle ä¸Šç•Œã€‚"

å…³é”®æ•°æ®ç‚¹ï¼š
- init_error=0 æ—¶æ‰€æœ‰æ–¹æ³•éƒ½æ¥è¿‘ oracleï¼ˆè¯æ˜ baseline æ²¡ bugï¼‰
- init_error=0.3 æ—¶ baseline å¤±æ•ˆï¼Œproposed ä»å·¥ä½œ
- basin è¾¹ç•Œçº¦ 0.3-0.5 samples
""")

    print(f"\nâœ… Done! All outputs saved to: {args.out_dir}")


if __name__ == "__main__":
    main()